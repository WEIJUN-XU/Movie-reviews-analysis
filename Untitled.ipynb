{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim import corpora\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stoplist = stopwords.words('english')\n",
    "\n",
    "#Set path and read data\n",
    "base_dir = 'IMDB/train/'\n",
    "pos_texts = open(base_dir + 'imdb_train_pos.txt').readlines()\n",
    "neg_texts = open(base_dir + 'imdb_train_neg.txt').readlines()\n",
    "\n",
    "#Data preprocessing functions\n",
    "def preprocess(texts):\n",
    "    texts = [re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\?:)<>]+|[+——！，\"\"。？、~@#￥%……&*（）]\", \" \",text) for text in texts]\n",
    "    texts = [\n",
    "        [word for word in document.lower().split() if word not in stoplist]\n",
    "        for document in texts]\n",
    "    \n",
    "    frequency = defaultdict(int)\n",
    "    for text in texts:\n",
    "        for token in text:\n",
    "            frequency[token] += 1\n",
    "            \n",
    "    texts = [\n",
    "        [token for token in text if frequency[token] > 10]\n",
    "        for text in texts]\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_texts = preprocess(pos_texts)\n",
    "neg_texts = preprocess(neg_texts)\n",
    "\n",
    "#After dividing the document into words, use corpora.Dictionary to generate a dictionary.\n",
    "pos_dictionary = corpora.Dictionary(pos_texts)\n",
    "neg_dictionary = corpora.Dictionary(neg_texts)\n",
    "#record keys and values of the dictionary\n",
    "df_pos = pd.DataFrame([pos_dictionary.cfs.keys(),pos_dictionary.cfs.values()]).T\n",
    "df_neg = pd.DataFrame([neg_dictionary.cfs.keys(),neg_dictionary.cfs.values()]).T\n",
    "\n",
    "#Name the columns for keys and valus\n",
    "df_pos.columns = ['pos_key','pos_freq']\n",
    "df_neg.columns = ['neg_key','neg_freq']\n",
    "\n",
    "df_pos['word'] = df_pos['pos_key'].apply(lambda x:pos_dictionary[x])\n",
    "df_neg['word'] = df_neg['neg_key'].apply(lambda x:neg_dictionary[x])\n",
    "#Connect data to df\n",
    "df = pd.merge(df_pos,df_neg,on=['word','word'],how='inner')\n",
    "df['dif'] = df['pos_freq']/df['neg_freq']\n",
    "\n",
    "df = df.sort_values(by = ['dif'],ascending=False).reset_index(drop=True)\n",
    "df['score'] = np.log(df['dif'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# construct features that only rely on train data\n",
    "N = 100\n",
    "pos_words = list(df['word'][:N])\n",
    "neg_words = list(df['word'][len(df)-N:])\n",
    "mid_words = list(df['word'][int((len(df)/2)-(N/2)):int((len(df)/2)+(N/2))])\n",
    "all_words = list(df['word'])\n",
    "word_score = dict(zip(list(df['word']),list(df['score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "pos_counts = []\n",
    "neg_counts = []\n",
    "y = []\n",
    "\n",
    "#Feature 1 calculate the average of all word scores\n",
    "#Feature 2 pos_words: count the top 100 words\n",
    "#Feature 3 neg_words: count the last 100 words\n",
    "for text in pos_texts:\n",
    "    inter_words = list(set(text).intersection(set(all_words)))\n",
    "    inter_pos = list(set(text).intersection(set(pos_words)))\n",
    "    inter_neg = list(set(text).intersection(set(neg_words)))\n",
    "    if len(inter_words) > 0:\n",
    "        score = np.mean([word_score[inter_words[i]] for i in range(len(inter_words))])\n",
    "    else:\n",
    "        score = 0\n",
    "    scores.append(score)\n",
    "    pos_counts.append(len(inter_pos))\n",
    "    neg_counts.append(len(inter_neg))\n",
    "    y.append(1)\n",
    "    \n",
    "for text in neg_texts:\n",
    "    inter_words = list(set(text).intersection(set(all_words)))\n",
    "    inter_pos = list(set(text).intersection(set(pos_words)))\n",
    "    inter_neg = list(set(text).intersection(set(neg_words)))\n",
    "    if len(inter_words) > 0:\n",
    "        score = np.mean([word_score[inter_words[i]] for i in range(len(inter_words))])\n",
    "    else:\n",
    "        score = 0\n",
    "    scores.append(score)\n",
    "    pos_counts.append(len(inter_pos))\n",
    "    neg_counts.append(len(inter_neg))\n",
    "    y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame([scores,pos_counts,neg_counts,y]).T\n",
    "train_data.columns = ['score','pos_count','neg_count','label']\n",
    "train_data = train_data.sample(frac=1)\n",
    "X_train = train_data.drop(['label'],axis=1)\n",
    "y_train = train_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.87      0.88      7517\n",
      "         1.0       0.87      0.89      0.88      7483\n",
      "\n",
      "    accuracy                           0.88     15000\n",
      "   macro avg       0.88      0.88      0.88     15000\n",
      "weighted avg       0.88      0.88      0.88     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "#Using the Gradient Boosting Decison Tree(GBDT) algorithm in sklearn to train model\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "print(classification_report(y_train,model.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the same method to process the test data and enter it into the trained model for testing\n",
    "base_dir = 'IMDB/test/'\n",
    "pos_texts = open(base_dir + 'imdb_test_pos.txt').readlines()\n",
    "neg_texts = open(base_dir + 'imdb_test_neg.txt').readlines()\n",
    "\n",
    "pos_texts = preprocess(pos_texts)\n",
    "neg_texts = preprocess(neg_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "pos_counts = []\n",
    "neg_counts = []\n",
    "y = []\n",
    "for text in pos_texts:\n",
    "    inter_words = list(set(text).intersection(set(all_words)))\n",
    "    inter_pos = list(set(text).intersection(set(pos_words)))\n",
    "    inter_neg = list(set(text).intersection(set(neg_words)))\n",
    "    if len(inter_words) > 0:\n",
    "        score = np.mean([word_score[inter_words[i]] for i in range(len(inter_words))])\n",
    "    else:\n",
    "        score = 0\n",
    "    scores.append(score)\n",
    "    pos_counts.append(len(inter_pos))\n",
    "    neg_counts.append(len(inter_neg))\n",
    "    y.append(1)\n",
    "    \n",
    "for text in neg_texts:\n",
    "    inter_words = list(set(text).intersection(set(all_words)))\n",
    "    inter_pos = list(set(text).intersection(set(pos_words)))\n",
    "    inter_neg = list(set(text).intersection(set(neg_words)))\n",
    "    if len(inter_words) > 0:\n",
    "        score = np.mean([word_score[inter_words[i]] for i in range(len(inter_words))])\n",
    "    else:\n",
    "        score = 0\n",
    "    scores.append(score)\n",
    "    pos_counts.append(len(inter_pos))\n",
    "    neg_counts.append(len(inter_neg))\n",
    "    y.append(0)\n",
    "    \n",
    "test_data = pd.DataFrame([scores,pos_counts,neg_counts,y]).T\n",
    "test_data.columns = ['score','pos_count','neg_count','label']\n",
    "test_data = test_data.sample(frac=1)\n",
    "X_test = test_data.drop(['label'],axis=1)\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.88      0.89      2501\n",
      "         1.0       0.88      0.90      0.89      2499\n",
      "\n",
      "    accuracy                           0.89      5000\n",
      "   macro avg       0.89      0.89      0.89      5000\n",
      "weighted avg       0.89      0.89      0.89      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/craig/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
